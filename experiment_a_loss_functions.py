"""
ì‹¤í—˜ A: ì†ì‹¤ í•¨ìˆ˜ ë¹„êµ (CrossEntropy Loss vs MSE Loss with softmax)

ëª©í‘œ: MSEì™€ CrossEntropyê°€ í•™ìŠµ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì°¨ì´ ë¶„ì„
- í•™ìŠµ ê³¡ì„ ì˜ ìˆ˜ë ´ ì†ë„, ì •í™•ë„, loss ì•ˆì •ì„± ë¹„êµ
- MSE ì‚¬ìš© ì‹œ Gradient Vanishing ë¬¸ì œ ë¶„ì„
- CrossEntropyì˜ ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„ì™€ ì•ˆì •ì„± í™•ì¸
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
from tqdm import tqdm
import warnings
import gc

warnings.filterwarnings("ignore")

# ì‹œê°í™” ì„¤ì •
plt.rcParams["font.family"] = "DejaVu Sans"
sns.set_style("whitegrid")


# GPU ì„¤ì • ìµœì í™”
def setup_device():
    """GPU ì„¤ì • ë° ìµœì í™”"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        # CUDA ìµœì í™” ì„¤ì •
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False

        # GPU ì •ë³´ ì¶œë ¥
        gpu_count = torch.cuda.device_count()
        current_gpu = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_gpu)

        print(f"ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥!")
        print(f"ğŸ“Š GPU ê°œìˆ˜: {gpu_count}")
        print(f"ğŸ¯ í˜„ì¬ GPU: {current_gpu} ({gpu_name})")

        # GPU ë©”ëª¨ë¦¬ ì •ë³´
        total_memory = torch.cuda.get_device_properties(current_gpu).total_memory / (
            1024**3
        )
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {total_memory:.1f} GB")

        return device, True
    else:
        print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return torch.device("cpu"), False


def clear_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()


class MLP(nn.Module):
    """ê¸°ë³¸ MLP ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°"""

    def __init__(self, input_size, num_classes):
        super(MLP, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_size, 256),  # ì…ë ¥ â†’ ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ (input_size â†’ 256)
            nn.ReLU(),  # í™œì„±í™” í•¨ìˆ˜ (ReLU)
            nn.Linear(256, 128),  # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ (256 â†’ 128)
            nn.ReLU(),  # í™œì„±í™” í•¨ìˆ˜ (ReLU)
            nn.Linear(128, num_classes),  # ì¶œë ¥ì¸µ (128 â†’ í´ë˜ìŠ¤ ê°œìˆ˜)
        )

    def forward(self, x):
        return self.model(x)


def load_fashion_mnist(use_gpu=True):
    """Fashion-MNIST ë°ì´í„°ì…‹ ë¡œë“œ (GPU ìµœì í™”)"""
    transform = transforms.Compose(
        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]  # ì •ê·œí™”
    )

    # í›ˆë ¨ ë°ì´í„°ì…‹
    train_dataset = torchvision.datasets.FashionMNIST(
        root="./data", train=True, download=True, transform=transform
    )

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
    test_dataset = torchvision.datasets.FashionMNIST(
        root="./data", train=False, download=True, transform=transform
    )

    # GPU ì‚¬ìš© ì‹œ ìµœì í™”ëœ DataLoader ì„¤ì •
    num_workers = 4 if use_gpu else 0
    pin_memory = use_gpu

    train_loader = DataLoader(
        train_dataset,
        batch_size=128,  # GPU ì‚¬ìš© ì‹œ ë°°ì¹˜ í¬ê¸° ì¦ê°€
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=128,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
    )

    return train_loader, test_loader, 28 * 28, 10


def load_digits_dataset(use_gpu=True):
    """Scikit-learn Digits ë°ì´í„°ì…‹ ë¡œë“œ (GPU ìµœì í™”)"""
    digits = load_digits()
    X, y = digits.data, digits.target

    # ë°ì´í„° ì •ê·œí™”
    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # PyTorch í…ì„œë¡œ ë³€í™˜
    X_train = torch.FloatTensor(X_train)
    X_test = torch.FloatTensor(X_test)
    y_train = torch.LongTensor(y_train)
    y_test = torch.LongTensor(y_test)

    # DataLoader ìƒì„±
    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)

    # GPU ì‚¬ìš© ì‹œ ìµœì í™”ëœ DataLoader ì„¤ì •
    num_workers = 2 if use_gpu else 0
    pin_memory = use_gpu

    train_loader = DataLoader(
        train_dataset,
        batch_size=64,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=64,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
    )

    return train_loader, test_loader, X.shape[1], 10


def train_model(
    model,
    train_loader,
    test_loader,
    loss_fn,
    optimizer,
    epochs,
    device,
    loss_name,
    use_amp=True,
):
    """ëª¨ë¸ í›ˆë ¨ í•¨ìˆ˜ (Mixed Precision ì§€ì›)"""
    model.to(device)

    # Mixed Precision ì„¤ì •
    scaler = torch.cuda.amp.GradScaler() if use_amp and device.type == "cuda" else None

    # ê¸°ë¡ìš© ë¦¬ìŠ¤íŠ¸ë“¤
    train_losses = []
    train_accuracies = []
    test_losses = []
    test_accuracies = []

    for epoch in tqdm(range(epochs), desc=f"Training with {loss_name}"):
        # í›ˆë ¨ ëª¨ë“œ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(
                device, non_blocking=True
            )

            # ì…ë ¥ ë°ì´í„°ë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜ (Fashion-MNISTì˜ ê²½ìš°)
            if len(inputs.shape) > 2:
                inputs = inputs.view(inputs.size(0), -1)

            optimizer.zero_grad(set_to_none=True)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

            # Mixed Precision Forward Pass
            if use_amp and device.type == "cuda":
                with torch.cuda.amp.autocast():
                    outputs = model(inputs)

                    # MSE Loss ì‚¬ìš© ì‹œ softmax ì ìš©
                    if isinstance(loss_fn, nn.MSELoss):
                        # One-hot encoding for MSE
                        labels_onehot = torch.zeros(labels.size(0), 10, device=device)
                        labels_onehot.scatter_(1, labels.unsqueeze(1), 1)

                        # Softmax ì ìš©
                        outputs = torch.softmax(outputs, dim=1)
                        loss = loss_fn(outputs, labels_onehot)

                        # ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•œ ì˜ˆì¸¡
                        _, predicted = torch.max(outputs.data, 1)
                    else:
                        # CrossEntropy Loss
                        loss = loss_fn(outputs, labels)
                        _, predicted = torch.max(outputs.data, 1)

                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(inputs)

                # MSE Loss ì‚¬ìš© ì‹œ softmax ì ìš©
                if isinstance(loss_fn, nn.MSELoss):
                    # One-hot encoding for MSE
                    labels_onehot = torch.zeros(labels.size(0), 10, device=device)
                    labels_onehot.scatter_(1, labels.unsqueeze(1), 1)

                    # Softmax ì ìš©
                    outputs = torch.softmax(outputs, dim=1)
                    loss = loss_fn(outputs, labels_onehot)

                    # ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•œ ì˜ˆì¸¡
                    _, predicted = torch.max(outputs.data, 1)
                else:
                    # CrossEntropy Loss
                    loss = loss_fn(outputs, labels)
                    _, predicted = torch.max(outputs.data, 1)

                loss.backward()
                optimizer.step()

            running_loss += loss.item()
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        # ì—í¬í¬ë³„ í›ˆë ¨ ì†ì‹¤ê³¼ ì •í™•ë„
        train_loss = running_loss / len(train_loader)
        train_acc = 100.0 * correct / total
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        # í…ŒìŠ¤íŠ¸ í‰ê°€
        model.eval()
        test_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device, non_blocking=True), labels.to(
                    device, non_blocking=True
                )

                if len(inputs.shape) > 2:
                    inputs = inputs.view(inputs.size(0), -1)

                # Mixed Precision Inference
                if use_amp and device.type == "cuda":
                    with torch.cuda.amp.autocast():
                        outputs = model(inputs)
                else:
                    outputs = model(inputs)

                if isinstance(loss_fn, nn.MSELoss):
                    labels_onehot = torch.zeros(labels.size(0), 10, device=device)
                    labels_onehot.scatter_(1, labels.unsqueeze(1), 1)
                    outputs = torch.softmax(outputs, dim=1)
                    loss = loss_fn(outputs, labels_onehot)
                    _, predicted = torch.max(outputs.data, 1)
                else:
                    loss = loss_fn(outputs, labels)
                    _, predicted = torch.max(outputs.data, 1)

                test_loss += loss.item()
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        test_loss = test_loss / len(test_loader)
        test_acc = 100.0 * correct / total
        test_losses.append(test_loss)
        test_accuracies.append(test_acc)

        # 10 ì—í¬í¬ë§ˆë‹¤ ì¶œë ¥ ë° GPU ë©”ëª¨ë¦¬ ì •ë³´
        if (epoch + 1) % 10 == 0:
            memory_info = ""
            if device.type == "cuda":
                allocated = torch.cuda.memory_allocated() / (1024**3)
                reserved = torch.cuda.memory_reserved() / (1024**3)
                memory_info = f", GPU Mem: {allocated:.1f}/{reserved:.1f} GB"

            print(
                f"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, "
                f"Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%{memory_info}"
            )

    return train_losses, train_accuracies, test_losses, test_accuracies


def analyze_gradient_flow(model, train_loader, loss_fn, device):
    """ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ë¶„ì„"""
    model.eval()
    gradients = []

    inputs, labels = next(iter(train_loader))
    inputs, labels = inputs.to(device, non_blocking=True), labels.to(
        device, non_blocking=True
    )

    if len(inputs.shape) > 2:
        inputs = inputs.view(inputs.size(0), -1)

    outputs = model(inputs)

    if isinstance(loss_fn, nn.MSELoss):
        labels_onehot = torch.zeros(labels.size(0), 10, device=device)
        labels_onehot.scatter_(1, labels.unsqueeze(1), 1)
        outputs = torch.softmax(outputs, dim=1)
        loss = loss_fn(outputs, labels_onehot)
    else:
        loss = loss_fn(outputs, labels)

    loss.backward()

    # ê° ë ˆì´ì–´ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ìˆ˜ì§‘
    for name, param in model.named_parameters():
        if param.grad is not None:
            gradients.append((name, param.grad.abs().mean().item()))

    return gradients


def plot_results(results_dict, dataset_name):
    """ê²°ê³¼ ì‹œê°í™”"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f"ì‹¤í—˜ A: ì†ì‹¤ í•¨ìˆ˜ ë¹„êµ ê²°ê³¼ ({dataset_name})", fontsize=16)

    # í›ˆë ¨ ì†ì‹¤
    axes[0, 0].set_title("Training Loss")
    for loss_name, metrics in results_dict.items():
        axes[0, 0].plot(metrics["train_losses"], label=loss_name)
    axes[0, 0].set_xlabel("Epoch")
    axes[0, 0].set_ylabel("Loss")
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # í…ŒìŠ¤íŠ¸ ì†ì‹¤
    axes[0, 1].set_title("Test Loss")
    for loss_name, metrics in results_dict.items():
        axes[0, 1].plot(metrics["test_losses"], label=loss_name)
    axes[0, 1].set_xlabel("Epoch")
    axes[0, 1].set_ylabel("Loss")
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # í›ˆë ¨ ì •í™•ë„
    axes[1, 0].set_title("Training Accuracy")
    for loss_name, metrics in results_dict.items():
        axes[1, 0].plot(metrics["train_accuracies"], label=loss_name)
    axes[1, 0].set_xlabel("Epoch")
    axes[1, 0].set_ylabel("Accuracy (%)")
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # í…ŒìŠ¤íŠ¸ ì •í™•ë„
    axes[1, 1].set_title("Test Accuracy")
    for loss_name, metrics in results_dict.items():
        axes[1, 1].plot(metrics["test_accuracies"], label=loss_name)
    axes[1, 1].set_xlabel("Epoch")
    axes[1, 1].set_ylabel("Accuracy (%)")
    axes[1, 1].legend()
    axes[1, 1].grid(True)

    plt.tight_layout()
    plt.savefig(
        f'experiment_a_results_{dataset_name.lower().replace("-", "_")}.png',
        dpi=300,
        bbox_inches="tight",
    )
    plt.show()


def create_comparison_table(results_dict):
    """ì •ëŸ‰ì  ë¹„êµ í‘œ ìƒì„±"""
    comparison_data = []

    for loss_name, metrics in results_dict.items():
        final_train_acc = metrics["train_accuracies"][-1]
        final_test_acc = metrics["test_accuracies"][-1]
        min_train_loss = min(metrics["train_losses"])
        min_test_loss = min(metrics["test_losses"])

        # ìˆ˜ë ´ê¹Œì§€ ê±¸ë¦° ì—í¬í¬ ìˆ˜ (í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ ìµœê³ ì ì˜ 95%ì— ë„ë‹¬í•œ ì‹œì )
        max_acc = max(metrics["test_accuracies"])
        convergence_threshold = max_acc * 0.95
        convergence_epoch = next(
            (
                i
                for i, acc in enumerate(metrics["test_accuracies"])
                if acc >= convergence_threshold
            ),
            len(metrics["test_accuracies"]),
        )

        comparison_data.append(
            {
                "ì†ì‹¤ í•¨ìˆ˜": loss_name,
                "ìµœì¢… í›ˆë ¨ ì •í™•ë„ (%)": f"{final_train_acc:.2f}",
                "ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„ (%)": f"{final_test_acc:.2f}",
                "ìµœì†Œ í›ˆë ¨ ì†ì‹¤": f"{min_train_loss:.4f}",
                "ìµœì†Œ í…ŒìŠ¤íŠ¸ ì†ì‹¤": f"{min_test_loss:.4f}",
                "ìˆ˜ë ´ê¹Œì§€ ê±¸ë¦° ì—í¬í¬": convergence_epoch + 1,
            }
        )

    df = pd.DataFrame(comparison_data)
    print("\n=== ì •ëŸ‰ì  ë¹„êµ ê²°ê³¼ ===")
    print(df.to_string(index=False))

    return df


def run_experiment_a():
    """ì‹¤í—˜ A ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ì‹¤í—˜ A: ì†ì‹¤ í•¨ìˆ˜ ë¹„êµ (CrossEntropy vs MSE with softmax)")
    print("=" * 60)

    # GPU ì„¤ì •
    device, use_gpu = setup_device()
    use_amp = use_gpu  # Mixed Precisionì€ GPUì—ì„œë§Œ ì‚¬ìš©

    # ì‹¤í—˜ ì„¤ì •
    epochs = 30
    learning_rate = 0.001 if use_gpu else 0.001

    # ë°ì´í„°ì…‹ë³„ ì‹¤í—˜
    datasets = [("Fashion-MNIST", load_fashion_mnist), ("Digits", load_digits_dataset)]

    for dataset_name, load_func in datasets:
        print(f"\n--- {dataset_name} ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜ ---")

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        clear_gpu_memory()

        # ë°ì´í„° ë¡œë“œ
        train_loader, test_loader, input_size, num_classes = load_func(use_gpu)

        # ì†ì‹¤ í•¨ìˆ˜ë“¤
        loss_functions = {
            "CrossEntropy": nn.CrossEntropyLoss(),
            "MSE (with softmax)": nn.MSELoss(),
        }

        results = {}

        for loss_name, loss_fn in loss_functions.items():
            print(f"\n{loss_name} ì†ì‹¤ í•¨ìˆ˜ë¡œ í•™ìŠµ ì¤‘...")

            # ëª¨ë¸ ì´ˆê¸°í™” (ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ê³µì •í•œ ë¹„êµ)
            model = MLP(input_size, num_classes)

            # GPU ì‚¬ìš© ì‹œ AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš© (ë” ì•ˆì •ì )
            if use_gpu:
                optimizer = optim.AdamW(
                    model.parameters(), lr=learning_rate, weight_decay=0.01
                )
            else:
                optimizer = optim.Adam(model.parameters(), lr=learning_rate)

            # ëª¨ë¸ í›ˆë ¨
            train_losses, train_accs, test_losses, test_accs = train_model(
                model,
                train_loader,
                test_loader,
                loss_fn,
                optimizer,
                epochs,
                device,
                loss_name,
                use_amp,
            )

            results[loss_name] = {
                "train_losses": train_losses,
                "train_accuracies": train_accs,
                "test_losses": test_losses,
                "test_accuracies": test_accs,
                "model": model,
            }

            # ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ë¶„ì„
            print(f"\n{loss_name} ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ ë¶„ì„:")
            gradients = analyze_gradient_flow(model, train_loader, loss_fn, device)
            for name, grad_val in gradients:
                print(f"  {name}: {grad_val:.6f}")

            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            del model, optimizer
            clear_gpu_memory()

        # ê²°ê³¼ ì‹œê°í™”
        plot_results(results, dataset_name)

        # ì •ëŸ‰ì  ë¹„êµ
        comparison_df = create_comparison_table(results)

        # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
        comparison_df.to_csv(
            f'experiment_a_comparison_{dataset_name.lower().replace("-", "_")}.csv',
            index=False,
            encoding="utf-8-sig",
        )


if __name__ == "__main__":
    # ì‹¤í—˜ A ì‹¤í–‰
    run_experiment_a()

    print("\n" + "=" * 60)
    print("ì‹¤í—˜ A ì™„ë£Œ!")
    print("ê²°ê³¼ íŒŒì¼ë“¤:")
    print("- experiment_a_results_fashion_mnist.png")
    print("- experiment_a_results_digits.png")
    print("- experiment_a_comparison_fashion_mnist.csv")
    print("- experiment_a_comparison_digits.csv")
    print("=" * 60)
