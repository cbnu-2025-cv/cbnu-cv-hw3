"""
ì‹¤í—˜ C: ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë¹„êµ (SGD vs SGD+Momentum vs Adam)

ëª©í‘œ: SGD, SGD+Momentum, Adamì˜ ì„±ëŠ¥ ë¹„êµ
- í•™ìŠµë¥  ë³€í™”ê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„ (0.1, 0.01, 0.001)
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬(Exponential Decay) ì ìš© íš¨ê³¼ ë¶„ì„
- Overshooting, ëŠë¦° ìˆ˜ë ´, ì•ˆì •ì„± í™•ì¸
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
from tqdm import tqdm
import warnings
import gc

warnings.filterwarnings("ignore")

# ì‹œê°í™” ì„¤ì •
plt.rcParams["font.family"] = "DejaVu Sans"
sns.set_style("whitegrid")


# GPU ì„¤ì • ìµœì í™”
def setup_device():
    """GPU ì„¤ì • ë° ìµœì í™”"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        # CUDA ìµœì í™” ì„¤ì •
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False

        # GPU ì •ë³´ ì¶œë ¥
        gpu_count = torch.cuda.device_count()
        current_gpu = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_gpu)

        print(f"ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥!")
        print(f"ğŸ“Š GPU ê°œìˆ˜: {gpu_count}")
        print(f"ğŸ¯ í˜„ì¬ GPU: {current_gpu} ({gpu_name})")

        # GPU ë©”ëª¨ë¦¬ ì •ë³´
        total_memory = torch.cuda.get_device_properties(current_gpu).total_memory / (
            1024**3
        )
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {total_memory:.1f} GB")

        return device, True
    else:
        print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return torch.device("cpu"), False


def clear_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()


class MLP(nn.Module):
    """ê¸°ë³¸ MLP ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°"""

    def __init__(self, input_size, num_classes):
        super(MLP, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_size, 256),  # ì…ë ¥ â†’ ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ
            nn.ReLU(),  # í™œì„±í™” í•¨ìˆ˜ (ReLU)
            nn.Linear(256, 128),  # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ
            nn.ReLU(),  # í™œì„±í™” í•¨ìˆ˜ (ReLU)
            nn.Linear(128, num_classes),  # ì¶œë ¥ì¸µ
        )

    def forward(self, x):
        return self.model(x)


def load_fashion_mnist(use_gpu=True):
    """Fashion-MNIST ë°ì´í„°ì…‹ ë¡œë“œ (GPU ìµœì í™”)"""
    transform = transforms.Compose(
        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]
    )

    train_dataset = torchvision.datasets.FashionMNIST(
        root="./data", train=True, download=True, transform=transform
    )
    test_dataset = torchvision.datasets.FashionMNIST(
        root="./data", train=False, download=True, transform=transform
    )

    # GPU ì‚¬ìš© ì‹œ ìµœì í™”ëœ DataLoader ì„¤ì •
    num_workers = 4 if use_gpu else 0
    pin_memory = use_gpu
    batch_size = 128 if use_gpu else 64  # GPU ì‚¬ìš© ì‹œ ë°°ì¹˜ í¬ê¸° ì¦ê°€

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
    )

    return train_loader, test_loader, 28 * 28, 10


def load_digits_dataset(use_gpu=True):
    """Scikit-learn Digits ë°ì´í„°ì…‹ ë¡œë“œ (GPU ìµœì í™”)"""
    digits = load_digits()
    X, y = digits.data, digits.target

    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    X_train = torch.FloatTensor(X_train)
    X_test = torch.FloatTensor(X_test)
    y_train = torch.LongTensor(y_train)
    y_test = torch.LongTensor(y_test)

    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)

    # GPU ì‚¬ìš© ì‹œ ìµœì í™”ëœ DataLoader ì„¤ì •
    num_workers = 2 if use_gpu else 0
    pin_memory = use_gpu
    batch_size = 64 if use_gpu else 32

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
    )

    return train_loader, test_loader, X.shape[1], 10


def create_optimizer(model_params, optimizer_name, learning_rate):
    """ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ìƒì„±"""
    if optimizer_name == "SGD":
        return optim.SGD(model_params, lr=learning_rate)
    elif optimizer_name == "SGD+Momentum":
        return optim.SGD(model_params, lr=learning_rate, momentum=0.9)
    elif optimizer_name == "Adam":
        return optim.Adam(model_params, lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")


def train_model_with_scheduler(
    model,
    train_loader,
    test_loader,
    optimizer,
    scheduler,
    epochs,
    device,
    optimizer_name,
    lr,
    use_scheduler=True,
    use_amp=True,
):
    """í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í¬í•¨í•œ ëª¨ë¸ í›ˆë ¨ (Mixed Precision ì§€ì›)"""
    model.to(device)
    criterion = nn.CrossEntropyLoss()

    # Mixed Precision ì„¤ì •
    scaler = torch.cuda.amp.GradScaler() if use_amp and device.type == "cuda" else None

    # ê¸°ë¡ìš© ë¦¬ìŠ¤íŠ¸ë“¤
    train_losses = []
    train_accuracies = []
    test_losses = []
    test_accuracies = []
    learning_rates = []  # í•™ìŠµë¥  ë³€í™” ê¸°ë¡
    gradient_norms = []  # ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ ê¸°ë¡

    for epoch in tqdm(range(epochs), desc=f"Training {optimizer_name} (lr={lr})"):
        # í›ˆë ¨ ëª¨ë“œ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        epoch_gradient_norms = []

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(
                device, non_blocking=True
            )

            # ì…ë ¥ ë°ì´í„°ë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜ (Fashion-MNISTì˜ ê²½ìš°)
            if len(inputs.shape) > 2:
                inputs = inputs.view(inputs.size(0), -1)

            optimizer.zero_grad(set_to_none=True)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

            # Mixed Precision Forward Pass
            if use_amp and device.type == "cuda":
                with torch.cuda.amp.autocast():
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)

                scaler.scale(loss).backward()

                # ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ ê³„ì‚° (ìŠ¤ì¼€ì¼ ê³ ë ¤)
                total_norm = 0
                for p in model.parameters():
                    if p.grad is not None:
                        param_norm = p.grad.data.norm(2)
                        total_norm += param_norm.item() ** 2
                total_norm = total_norm ** (1.0 / 2)
                epoch_gradient_norms.append(total_norm / scaler.get_scale())

                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()

                # ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ ê³„ì‚°
                total_norm = 0
                for p in model.parameters():
                    if p.grad is not None:
                        param_norm = p.grad.data.norm(2)
                        total_norm += param_norm.item() ** 2
                total_norm = total_norm ** (1.0 / 2)
                epoch_gradient_norms.append(total_norm)

                optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš©
        if use_scheduler and scheduler is not None:
            scheduler.step()

        # ì—í¬í¬ë³„ ê¸°ë¡
        train_loss = running_loss / len(train_loader)
        train_acc = 100.0 * correct / total
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        # í˜„ì¬ í•™ìŠµë¥  ê¸°ë¡
        current_lr = optimizer.param_groups[0]["lr"]
        learning_rates.append(current_lr)

        # í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ ê¸°ë¡
        avg_grad_norm = np.mean(epoch_gradient_norms) if epoch_gradient_norms else 0
        gradient_norms.append(avg_grad_norm)

        # í…ŒìŠ¤íŠ¸ í‰ê°€
        model.eval()
        test_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device, non_blocking=True), labels.to(
                    device, non_blocking=True
                )

                if len(inputs.shape) > 2:
                    inputs = inputs.view(inputs.size(0), -1)

                # Mixed Precision Inference
                if use_amp and device.type == "cuda":
                    with torch.cuda.amp.autocast():
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)
                else:
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)

                test_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        test_loss = test_loss / len(test_loader)
        test_acc = 100.0 * correct / total
        test_losses.append(test_loss)
        test_accuracies.append(test_acc)

        # 20 ì—í¬í¬ë§ˆë‹¤ ì¶œë ¥ ë° GPU ë©”ëª¨ë¦¬ ì •ë³´
        if (epoch + 1) % 20 == 0:
            memory_info = ""
            if device.type == "cuda":
                allocated = torch.cuda.memory_allocated() / (1024**3)
                reserved = torch.cuda.memory_reserved() / (1024**3)
                memory_info = f", GPU Mem: {allocated:.1f}/{reserved:.1f} GB"

            print(
                f"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, "
                f"Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, "
                f"Test Acc: {test_acc:.2f}%, LR: {current_lr:.6f}{memory_info}"
            )

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 50 ì—í¬í¬ë§ˆë‹¤)
        if epoch % 50 == 0 and device.type == "cuda":
            clear_gpu_memory()

    return {
        "train_losses": train_losses,
        "train_accuracies": train_accuracies,
        "test_losses": test_losses,
        "test_accuracies": test_accuracies,
        "learning_rates": learning_rates,
        "gradient_norms": gradient_norms,
    }


def analyze_convergence_stability(losses, window_size=10):
    """ìˆ˜ë ´ ì•ˆì •ì„± ë¶„ì„"""
    if len(losses) < window_size:
        return {"volatility": 0, "final_trend": 0}

    # ìµœê·¼ window_size êµ¬ê°„ì˜ ë³€ë™ì„± ê³„ì‚°
    recent_losses = losses[-window_size:]
    volatility = np.std(recent_losses)

    # ìµœê·¼ êµ¬ê°„ì˜ íŠ¸ë Œë“œ (ê¸°ìš¸ê¸°)
    x = np.arange(len(recent_losses))
    trend = np.polyfit(x, recent_losses, 1)[0]  # 1ì°¨ ë‹¤í•­ì‹ì˜ ê¸°ìš¸ê¸°

    return {"volatility": volatility, "final_trend": trend}


def plot_comprehensive_results(results_dict, dataset_name, learning_rate):
    """í¬ê´„ì ì¸ ê²°ê³¼ ì‹œê°í™”"""
    fig, axes = plt.subplots(3, 2, figsize=(15, 18))
    fig.suptitle(
        f"ì‹¤í—˜ C: ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ({dataset_name}, LR={learning_rate})",
        fontsize=16,
    )

    # 1. í›ˆë ¨ ì†ì‹¤
    axes[0, 0].set_title("Training Loss")
    for opt_name, results in results_dict.items():
        axes[0, 0].plot(results["train_losses"], label=opt_name)
    axes[0, 0].set_xlabel("Epoch")
    axes[0, 0].set_ylabel("Loss")
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    axes[0, 0].set_yscale("log")  # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ë³€í™” íŒ¨í„´ ê°•ì¡°

    # 2. í…ŒìŠ¤íŠ¸ ì •í™•ë„
    axes[0, 1].set_title("Test Accuracy")
    for opt_name, results in results_dict.items():
        axes[0, 1].plot(results["test_accuracies"], label=opt_name)
    axes[0, 1].set_xlabel("Epoch")
    axes[0, 1].set_ylabel("Accuracy (%)")
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # 3. í•™ìŠµë¥  ë³€í™”
    axes[1, 0].set_title("Learning Rate Schedule")
    for opt_name, results in results_dict.items():
        axes[1, 0].plot(results["learning_rates"], label=opt_name)
    axes[1, 0].set_xlabel("Epoch")
    axes[1, 0].set_ylabel("Learning Rate")
    axes[1, 0].legend()
    axes[1, 0].grid(True)
    axes[1, 0].set_yscale("log")

    # 4. ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„
    axes[1, 1].set_title("Gradient Norm")
    for opt_name, results in results_dict.items():
        axes[1, 1].plot(results["gradient_norms"], label=opt_name, alpha=0.7)
    axes[1, 1].set_xlabel("Epoch")
    axes[1, 1].set_ylabel("Gradient Norm")
    axes[1, 1].legend()
    axes[1, 1].grid(True)
    axes[1, 1].set_yscale("log")

    # 5. ì†ì‹¤ ìŠ¤ë¬´ë”© (ì´ë™í‰ê· )
    axes[2, 0].set_title("Smoothed Training Loss (Moving Average)")
    window_size = 5
    for opt_name, results in results_dict.items():
        losses = results["train_losses"]
        if len(losses) >= window_size:
            smoothed = pd.Series(losses).rolling(window=window_size).mean()
            axes[2, 0].plot(smoothed, label=opt_name)
    axes[2, 0].set_xlabel("Epoch")
    axes[2, 0].set_ylabel("Smoothed Loss")
    axes[2, 0].legend()
    axes[2, 0].grid(True)

    # 6. ìˆ˜ë ´ ë¶„ì„ (ìµœê·¼ êµ¬ê°„ í™•ëŒ€)
    axes[2, 1].set_title("Convergence Analysis (Last 20 Epochs)")
    for opt_name, results in results_dict.items():
        recent_losses = results["test_losses"][-20:]
        axes[2, 1].plot(
            range(len(results["test_losses"]) - 20, len(results["test_losses"])),
            recent_losses,
            label=opt_name,
            marker="o",
            markersize=3,
        )
    axes[2, 1].set_xlabel("Epoch")
    axes[2, 1].set_ylabel("Test Loss")
    axes[2, 1].legend()
    axes[2, 1].grid(True)

    plt.tight_layout()
    filename = f'experiment_c_results_{dataset_name.lower().replace("-", "_")}_lr_{str(learning_rate).replace(".", "_")}.png'
    plt.savefig(filename, dpi=300, bbox_inches="tight")
    plt.show()

    return filename


def create_detailed_comparison_table(all_results, learning_rates):
    """í•™ìŠµë¥ ë³„ ìƒì„¸ ë¹„êµ í‘œ ìƒì„±"""
    comparison_data = []

    for lr in learning_rates:
        for dataset_name, dataset_results in all_results.items():
            if lr not in dataset_results:
                continue

            for opt_name, results in dataset_results[lr].items():
                final_train_acc = results["train_accuracies"][-1]
                final_test_acc = results["test_accuracies"][-1]
                min_train_loss = min(results["train_losses"])
                best_test_acc = max(results["test_accuracies"])

                # ìˆ˜ë ´ ì†ë„ (ìµœê³  ì •í™•ë„ì˜ 95%ì— ë„ë‹¬í•œ ì‹œì )
                convergence_threshold = best_test_acc * 0.95
                convergence_epoch = next(
                    (
                        i
                        for i, acc in enumerate(results["test_accuracies"])
                        if acc >= convergence_threshold
                    ),
                    len(results["test_accuracies"]),
                )

                # ì•ˆì •ì„± ë¶„ì„
                stability = analyze_convergence_stability(results["test_losses"])

                # í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„
                avg_grad_norm = np.mean(results["gradient_norms"])

                comparison_data.append(
                    {
                        "ë°ì´í„°ì…‹": dataset_name,
                        "ìµœì í™”ê¸°": opt_name,
                        "í•™ìŠµë¥ ": lr,
                        "ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„ (%)": f"{final_test_acc:.2f}",
                        "ìµœê³  í…ŒìŠ¤íŠ¸ ì •í™•ë„ (%)": f"{best_test_acc:.2f}",
                        "ìµœì†Œ í›ˆë ¨ ì†ì‹¤": f"{min_train_loss:.4f}",
                        "ìˆ˜ë ´ ì†ë„ (epochs)": convergence_epoch + 1,
                        "ì•ˆì •ì„± (ë³€ë™ì„±)": f"{stability['volatility']:.4f}",
                        "í‰ê·  Gradient Norm": f"{avg_grad_norm:.4f}",
                    }
                )

    df = pd.DataFrame(comparison_data)
    return df


def plot_learning_rate_comparison(all_results, dataset_name, optimizer_name):
    """í•™ìŠµë¥ ë³„ ë¹„êµ ì‹œê°í™”"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f"{optimizer_name} - í•™ìŠµë¥ ë³„ ë¹„êµ ({dataset_name})", fontsize=16)

    colors = ["blue", "red", "green"]

    for idx, (lr, color) in enumerate(zip([0.1, 0.01, 0.001], colors)):
        if lr not in all_results[dataset_name]:
            continue
        if optimizer_name not in all_results[dataset_name][lr]:
            continue

        results = all_results[dataset_name][lr][optimizer_name]

        # í›ˆë ¨ ì†ì‹¤
        axes[0, 0].plot(results["train_losses"], label=f"LR={lr}", color=color)
        axes[0, 0].set_title("Training Loss")
        axes[0, 0].set_xlabel("Epoch")
        axes[0, 0].set_ylabel("Loss")
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        axes[0, 0].set_yscale("log")

        # í…ŒìŠ¤íŠ¸ ì •í™•ë„
        axes[0, 1].plot(results["test_accuracies"], label=f"LR={lr}", color=color)
        axes[0, 1].set_title("Test Accuracy")
        axes[0, 1].set_xlabel("Epoch")
        axes[0, 1].set_ylabel("Accuracy (%)")
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # í•™ìŠµë¥  ë³€í™”
        axes[1, 0].plot(results["learning_rates"], label=f"LR={lr}", color=color)
        axes[1, 0].set_title("Learning Rate Schedule")
        axes[1, 0].set_xlabel("Epoch")
        axes[1, 0].set_ylabel("Learning Rate")
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        axes[1, 0].set_yscale("log")

        # ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„
        axes[1, 1].plot(
            results["gradient_norms"], label=f"LR={lr}", color=color, alpha=0.7
        )
        axes[1, 1].set_title("Gradient Norm")
        axes[1, 1].set_xlabel("Epoch")
        axes[1, 1].set_ylabel("Gradient Norm")
        axes[1, 1].legend()
        axes[1, 1].grid(True)
        axes[1, 1].set_yscale("log")

    plt.tight_layout()
    filename = (
        f'lr_comparison_{optimizer_name}_{dataset_name.lower().replace("-", "_")}.png'
    )
    plt.savefig(filename, dpi=300, bbox_inches="tight")
    plt.show()

    return filename


def run_experiment_c():
    """ì‹¤í—˜ C ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ì‹¤í—˜ C: ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë¹„êµ (SGD vs SGD+Momentum vs Adam)")
    print("=" * 60)

    # GPU ì„¤ì •
    device, use_gpu = setup_device()
    use_amp = use_gpu  # Mixed Precisionì€ GPUì—ì„œë§Œ ì‚¬ìš©

    # ì‹¤í—˜ ì„¤ì •
    epochs = 100
    learning_rates = [0.1, 0.01, 0.001]
    optimizers = ["SGD", "SGD+Momentum", "Adam"]
    use_scheduler = True  # Exponential Decay ì‚¬ìš© ì—¬ë¶€

    # ë°ì´í„°ì…‹ë³„ ì‹¤í—˜
    datasets = [("Fashion-MNIST", load_fashion_mnist), ("Digits", load_digits_dataset)]

    all_results = {}

    for dataset_name, load_func in datasets:
        print(f"\n{'='*50}")
        print(f"--- {dataset_name} ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜ ---")
        print(f"{'='*50}")

        # ë°ì´í„° ë¡œë“œ
        train_loader, test_loader, input_size, num_classes = load_func(use_gpu)

        all_results[dataset_name] = {}

        for lr in learning_rates:
            print(f"\n--- í•™ìŠµë¥  {lr} ---")
            all_results[dataset_name][lr] = {}

            results_for_lr = {}

            for optimizer_name in optimizers:
                print(f"\n{optimizer_name} (LR={lr}) ìµœì í™”ê¸°ë¡œ í•™ìŠµ ì¤‘...")

                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                clear_gpu_memory()

                # ëª¨ë¸ ì´ˆê¸°í™” (ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ê³µì •í•œ ë¹„êµ)
                model = MLP(input_size, num_classes)

                # ìµœì í™”ê¸° ìƒì„±
                optimizer = create_optimizer(model.parameters(), optimizer_name, lr)

                # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„± (Exponential Decay)
                scheduler = None
                if use_scheduler:
                    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)

                # ëª¨ë¸ í›ˆë ¨
                results = train_model_with_scheduler(
                    model,
                    train_loader,
                    test_loader,
                    optimizer,
                    scheduler,
                    epochs,
                    device,
                    optimizer_name,
                    lr,
                    use_scheduler,
                    use_amp,
                )

                results_for_lr[optimizer_name] = results
                all_results[dataset_name][lr][optimizer_name] = results

                print(f"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {results['test_accuracies'][-1]:.2f}%")
                print(f"ìµœê³  í…ŒìŠ¤íŠ¸ ì •í™•ë„: {max(results['test_accuracies']):.2f}%")

                # ëª¨ë¸ ì‚­ì œ ë° GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                del model, optimizer
                if scheduler:
                    del scheduler
                clear_gpu_memory()

            # í•™ìŠµë¥ ë³„ ê²°ê³¼ ì‹œê°í™”
            plot_filename = plot_comprehensive_results(results_for_lr, dataset_name, lr)
            print(f"ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: {plot_filename}")

        # ìµœì í™”ê¸°ë³„ í•™ìŠµë¥  ë¹„êµ
        for optimizer_name in optimizers:
            lr_comp_filename = plot_learning_rate_comparison(
                all_results, dataset_name, optimizer_name
            )
            print(f"í•™ìŠµë¥  ë¹„êµ ê·¸ë˜í”„ ì €ì¥: {lr_comp_filename}")

    # ì „ì²´ ê²°ê³¼ ì •ëŸ‰ì  ë¹„êµ
    print("\n" + "=" * 60)
    print("ì „ì²´ ì‹¤í—˜ ê²°ê³¼ ì •ëŸ‰ì  ë¹„êµ")
    print("=" * 60)

    comparison_df = create_detailed_comparison_table(all_results, learning_rates)
    print(comparison_df.to_string(index=False))

    # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
    comparison_df.to_csv(
        "experiment_c_comprehensive_comparison.csv", index=False, encoding="utf-8-sig"
    )

    # ìµœê³  ì„±ëŠ¥ ë¶„ì„
    print("\n" + "=" * 40)
    print("ìµœê³  ì„±ëŠ¥ ë¶„ì„")
    print("=" * 40)

    for dataset_name in all_results.keys():
        print(f"\n{dataset_name} ë°ì´í„°ì…‹:")
        best_accuracy = 0
        best_config = None

        for lr in learning_rates:
            for opt_name in optimizers:
                if (
                    lr in all_results[dataset_name]
                    and opt_name in all_results[dataset_name][lr]
                ):
                    max_acc = max(
                        all_results[dataset_name][lr][opt_name]["test_accuracies"]
                    )
                    if max_acc > best_accuracy:
                        best_accuracy = max_acc
                        best_config = (opt_name, lr)

        if best_config:
            print(
                f"  ìµœê³  ì„±ëŠ¥: {best_config[0]} (LR={best_config[1]}) - {best_accuracy:.2f}%"
            )


if __name__ == "__main__":
    # ì‹¤í—˜ C ì‹¤í–‰
    run_experiment_c()

    print("\n" + "=" * 60)
    print("ì‹¤í—˜ C ì™„ë£Œ!")
    print("ê²°ê³¼ íŒŒì¼ë“¤:")
    print("- experiment_c_results_*.png (í•™ìŠµë¥ ë³„ ìƒì„¸ ê²°ê³¼)")
    print("- lr_comparison_*.png (ìµœì í™”ê¸°ë³„ í•™ìŠµë¥  ë¹„êµ)")
    print("- experiment_c_comprehensive_comparison.csv (ì „ì²´ ì •ëŸ‰ì  ë¹„êµ)")
    print("=" * 60)
